"""
Tool: sar_analysis
Generated by Tool Builder Agent

Performs structure-activity relationship (SAR) analysis on molecular datasets. Analyzes correlations between molecular descriptors/substructures and activity responses, identifies activity cliffs, and provides representative examples. Accepts dataset names and flexible column specifications for SMILES and response variables. Automatically infers response column if not specified. Returns a comprehensive text summary of SAR findings and optionally saves supporting data/visualizations.

Examples:
1. sar_analysis("drug_screening_data", smiles_cols="molecule_smiles", response="ic50_value", out_dataset="sar_results")
# Analyzes structure-activity relationships in drug screening dataset, using IC50 values as response, saves detailed results
2. sar_analysis("reaction_yields", out_dataset="reaction_sar") 
# Auto-detects SMILES and response columns in reaction dataset, performs SAR analysis and saves supporting data

Data Inputs: dataset (string): Name of dataset containing molecular structures and activity data
smiles_cols (string or list, optional): Column name(s) containing SMILES structures
response (string, optional): Column name for numeric response/activity values
features (string, optional): Name of dataset containing precomputed molecular features
Data Outputs: Text summary of SAR analysis findings including descriptor correlations, activity cliffs, and representative examples
Optional: Supporting datasets saved with specified out_dataset prefix
Optional: Correlation visualization plot saved to output directory
"""

import numpy as np
import pandas as pd
import pyarrow as pa
from typing import Any

# Tool implementation
def sar_analysis(dataset, smiles_cols=None, response=None, out_dataset=None, features=None, *, db, config) -> str:
    """
    Perform structure-activity relationship analysis on molecular dataset.
    
    Args:
        dataset: Name of dataset containing molecular data
        smiles_cols: Column name(s) for SMILES structures (str or list)
        response: Column name for numeric response/activity values
        out_dataset: Optional name to save supporting analysis tables
        features: Optional dataset name containing precomputed molecular features
    
    Returns:
        String summary of SAR analysis findings
    """
    import pandas as pd
    import numpy as np
    from rdkit import Chem
    from rdkit.Chem import Descriptors, rdMolDescriptors
    import os
    
    try:
        # Load main dataset
        try:
            data = db.get_table(dataset).to_pandas()
        except Exception as e:
            return f"Error loading dataset '{dataset}': {str(e)}"
        
        if data.empty:
            return f"Dataset '{dataset}' is empty"
        
        # Handle SMILES columns
        if smiles_cols is None:
            # Try common SMILES column names
            smiles_candidates = ['smiles', 'SMILES', 'smi', 'structure', 'mol']
            smiles_cols = None
            for col in smiles_candidates:
                if col in data.columns:
                    smiles_cols = col
                    break
            if smiles_cols is None:
                return "No SMILES column found. Please specify smiles_cols parameter."
        
        # Ensure smiles_cols is a list
        if isinstance(smiles_cols, str):
            smiles_cols = [smiles_cols]
        
        # Validate SMILES columns exist
        missing_cols = [col for col in smiles_cols if col not in data.columns]
        if missing_cols:
            return f"SMILES columns not found: {missing_cols}"
        
        # Use first SMILES column for analysis
        smiles_col = smiles_cols[0]
        
        # Handle response column
        if response is None:
            # Try to infer response column
            response_candidates = ['yield', 'response', 'target', 'activity', 'value', 'y']
            response = None
            for col in response_candidates:
                if col in data.columns and pd.api.types.is_numeric_dtype(data[col]):
                    response = col
                    break
            if response is None:
                return "No numeric response column found. Please specify response parameter."
            used_response = f"Auto-detected response column: '{response}'"
        else:
            if response not in data.columns:
                return f"Response column '{response}' not found in dataset"
            if not pd.api.types.is_numeric_dtype(data[response]):
                return f"Response column '{response}' is not numeric"
            used_response = f"Using specified response column: '{response}'"
        
        # Clean data
        data = data.dropna(subset=[smiles_col, response])
        if len(data) == 0:
            return "No valid SMILES-response pairs found after cleaning"
        
        # Load or compute molecular features
        if features is not None:
            try:
                feature_data = db.get_table(features).to_pandas()
                # Assume features dataset has same index/order as main dataset
                if len(feature_data) != len(data):
                    return f"Feature dataset length ({len(feature_data)}) doesn't match main dataset ({len(data)})"
                descriptors_df = feature_data
            except Exception as e:
                return f"Error loading features dataset '{features}': {str(e)}"
        else:
            # Compute basic molecular descriptors
            descriptors = []
            valid_indices = []
            
            for idx, smiles in enumerate(data[smiles_col]):
                try:
                    mol = Chem.MolFromSmiles(smiles)
                    if mol is not None:
                        desc = {
                            'MW': Descriptors.MolWt(mol),
                            'LogP': Descriptors.MolLogP(mol),
                            'HBD': rdMolDescriptors.CalcNumHBD(mol),
                            'HBA': rdMolDescriptors.CalcNumHBA(mol),
                            'TPSA': rdMolDescriptors.CalcTPSA(mol),
                            'RotBonds': rdMolDescriptors.CalcNumRotatableBonds(mol),
                            'AromaticRings': rdMolDescriptors.CalcNumAromaticRings(mol),
                            'HeavyAtoms': mol.GetNumHeavyAtoms()
                        }
                        descriptors.append(desc)
                        valid_indices.append(idx)
                except:
                    continue
            
            if not descriptors:
                return "No valid molecular structures found for descriptor calculation"
            
            descriptors_df = pd.DataFrame(descriptors)
            data = data.iloc[valid_indices].reset_index(drop=True)
        
        # Perform SAR analysis
        response_values = data[response].values
        
        # 1. Descriptor correlations
        correlations = {}
        for col in descriptors_df.columns:
            if pd.api.types.is_numeric_dtype(descriptors_df[col]):
                corr = np.corrcoef(descriptors_df[col].values, response_values)[0, 1]
                if not np.isnan(corr):
                    correlations[col] = corr
        
        # Sort by absolute correlation
        sorted_corrs = sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True)
        
        # 2. Activity cliffs detection (simplified)
        # Find pairs of similar structures with large activity differences
        activity_cliffs = []
        if len(data) > 1:
            # Use Tanimoto similarity approximation based on descriptors
            from sklearn.metrics.pairwise import cosine_similarity
            desc_matrix = descriptors_df.select_dtypes(include=[np.number]).fillna(0)
            if not desc_matrix.empty:
                # Normalize descriptors
                desc_normalized = (desc_matrix - desc_matrix.mean()) / (desc_matrix.std() + 1e-8)
                similarities = cosine_similarity(desc_normalized)
                
                # Find high similarity, high activity difference pairs
                for i in range(len(data)):
                    for j in range(i+1, len(data)):
                        sim = similarities[i, j]
                        act_diff = abs(response_values[i] - response_values[j])
                        if sim > 0.8 and act_diff > np.std(response_values):  # Threshold for cliff
                            activity_cliffs.append({
                                'idx1': i, 'idx2': j, 
                                'similarity': sim, 
                                'activity_diff': act_diff,
                                'smiles1': data.iloc[i][smiles_col],
                                'smiles2': data.iloc[j][smiles_col],
                                'response1': response_values[i],
                                'response2': response_values[j]
                            })
        
        # Sort cliffs by activity difference
        activity_cliffs = sorted(activity_cliffs, key=lambda x: x['activity_diff'], reverse=True)[:5]
        
        # 3. Representative examples
        # High, medium, low activity examples
        sorted_indices = np.argsort(response_values)
        n_examples = min(3, len(data))
        
        high_idx = sorted_indices[-1] if len(sorted_indices) > 0 else 0
        low_idx = sorted_indices[0] if len(sorted_indices) > 0 else 0
        mid_idx = sorted_indices[len(sorted_indices)//2] if len(sorted_indices) > 2 else high_idx
        
        examples = {
            'high': {'idx': high_idx, 'smiles': data.iloc[high_idx][smiles_col], 'response': response_values[high_idx]},
            'low': {'idx': low_idx, 'smiles': data.iloc[low_idx][smiles_col], 'response': response_values[low_idx]}
        }
        if mid_idx != high_idx and mid_idx != low_idx:
            examples['medium'] = {'idx': mid_idx, 'smiles': data.iloc[mid_idx][smiles_col], 'response': response_values[mid_idx]}
        
        # Generate summary report
        summary_lines = [
            f"=== Structure-Activity Relationship Analysis ===",
            f"Dataset: {dataset}",
            f"{used_response}",
            f"Analyzed {len(data)} compounds",
            f"Response range: {np.min(response_values):.3f} to {np.max(response_values):.3f}",
            f"Response mean ± std: {np.mean(response_values):.3f} ± {np.std(response_values):.3f}",
            "",
            "=== Top Descriptor Correlations ===",
        ]
        
        for desc, corr in sorted_corrs[:5]:
            summary_lines.append(f"{desc}: r = {corr:.3f}")
        
        if activity_cliffs:
            summary_lines.extend([
                "",
                "=== Activity Cliffs Detected ===",
                f"Found {len(activity_cliffs)} potential activity cliffs:"
            ])
            for i, cliff in enumerate(activity_cliffs[:3]):
                summary_lines.append(f"Cliff {i+1}: Similarity = {cliff['similarity']:.3f}, "
                                   f"Activity difference = {cliff['activity_diff']:.3f}")
        else:
            summary_lines.extend([
                "",
                "=== Activity Cliffs ===",
                "No significant activity cliffs detected"
            ])
        
        summary_lines.extend([
            "",
            "=== Representative Examples ===",
        ])
        
        for level, example in examples.items():
            summary_lines.append(f"{level.capitalize()} activity: {example['response']:.3f} "
                               f"(SMILES: {example['smiles'][:50]}{'...' if len(example['smiles']) > 50 else ''})")
        
        # Save supporting data if requested
        if out_dataset:
            try:
                # Prepare analysis results
                analysis_results = data.copy()
                analysis_results = pd.concat([analysis_results, descriptors_df], axis=1)
                
                # Add correlation info
                corr_df = pd.DataFrame(sorted_corrs, columns=['Descriptor', 'Correlation'])
                
                # Save main results
                db.save_table(f"{out_dataset}_results", analysis_results)
                db.save_table(f"{out_dataset}_correlations", corr_df)
                
                if activity_cliffs:
                    cliffs_df = pd.DataFrame(activity_cliffs)
                    db.save_table(f"{out_dataset}_cliffs", cliffs_df)
                
                summary_lines.append(f"\nSupporting data saved to: {out_dataset}_results, {out_dataset}_correlations" + 
                                    (f", {out_dataset}_cliffs" if activity_cliffs else ""))
                
                # Save visualization if output path available
                if 'output_path' in config:
                    try:
                        import matplotlib.pyplot as plt
                        
                        # Create correlation plot
                        if len(sorted_corrs) > 0:
                            fig, ax = plt.subplots(figsize=(10, 6))
                            descs, corrs = zip(*sorted_corrs[:10])
                            colors = ['red' if c < 0 else 'blue' for c in corrs]
                            ax.barh(range(len(corrs)), corrs, color=colors, alpha=0.7)
                            ax.set_yticks(range(len(corrs)))
                            ax.set_yticklabels(descs)
                            ax.set_xlabel('Correlation with Response')
                            ax.set_title('Top Descriptor-Activity Correlations')
                            ax.axvline(x=0, color='black', linestyle='-', alpha=0.3)
                            plt.tight_layout()
                            
                            plot_path = os.path.join(config['output_path'], f'sar_correlations_{dataset}.png')
                            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
                            plt.close()
                            
                            summary_lines.append(f"Correlation plot saved to: {plot_path}")
                    except Exception as e:
                        summary_lines.append(f"Note: Could not save visualization: {str(e)}")
                        
            except Exception as e:
                summary_lines.append(f"Warning: Could not save supporting data: {str(e)}")
        
        return "\n".join(summary_lines)
        
    except Exception as e:
        return f"Error in SAR analysis: {str(e)}"

# Tool metadata for registration
TOOL_METADATA = {'name': 'sar_analysis', 'description': 'Performs structure-activity relationship (SAR) analysis on molecular datasets. Analyzes correlations between molecular descriptors/substructures and activity responses, identifies activity cliffs, and provides representative examples. Accepts dataset names and flexible column specifications for SMILES and response variables. Automatically infers response column if not specified. Returns a comprehensive text summary of SAR findings and optionally saves supporting data/visualizations.', 'examples': ['sar_analysis("drug_screening_data", smiles_cols="molecule_smiles", response="ic50_value", out_dataset="sar_results")\n# Analyzes structure-activity relationships in drug screening dataset, using IC50 values as response, saves detailed results', 'sar_analysis("reaction_yields", out_dataset="reaction_sar") \n# Auto-detects SMILES and response columns in reaction dataset, performs SAR analysis and saves supporting data'], 'data_inputs': 'dataset (string): Name of dataset containing molecular structures and activity data\nsmiles_cols (string or list, optional): Column name(s) containing SMILES structures\nresponse (string, optional): Column name for numeric response/activity values\nfeatures (string, optional): Name of dataset containing precomputed molecular features', 'data_outputs': 'Text summary of SAR analysis findings including descriptor correlations, activity cliffs, and representative examples\nOptional: Supporting datasets saved with specified out_dataset prefix\nOptional: Correlation visualization plot saved to output directory'}
